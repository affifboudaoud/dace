{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dace as dc\n",
    "from dace.autodiff import add_backward_pass\n",
    "from dace.transformation.auto.auto_optimize import auto_optimize\n",
    "from dace.dtypes import DeviceType\n",
    "import jax\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define matrix dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NI, NJ, NK, NL = 32, 36, 38, 42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the DaCe program for the k2mm computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dc.program\n",
    "def k2mm(alpha: dc.float64, beta: dc.float64, A: dc.float64[NI, NK], B: dc.float64[NK, NJ], C: dc.float64[NJ, NL],\n",
    "         D: dc.float64[NI, NL], S: dc.float64[1]):\n",
    "    \"\"\"\n",
    "    Computes D = alpha * A @ B @ C + beta * D\n",
    "    Computes S = sum(D)\n",
    "    \"\"\"\n",
    "    D[:] = alpha * A @ B @ C + beta * D\n",
    "    S[0] = np.sum(D)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize scalar parameters and matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha, beta = 0.2, 1.2\n",
    "A = np.ones((NI, NK))\n",
    "B = np.ones((NK, NJ))\n",
    "C = np.ones((NJ, NL))\n",
    "D = np.ones((NI, NL))\n",
    "gradient_A = np.zeros((NI, NK))\n",
    "gradient_S = np.ones((1))\n",
    "S = np.zeros((1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert DaCe program to an SDFG and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bd9e4008e341d48fc0fba4437169472f243f6ee1cc442100e35835f01ab6e0c4'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdfg = k2mm.to_sdfg(alpha=alpha, beta=beta, A=A, B=B, C=C, D=D)\n",
    "sdfg.save(\"log_sdfgs/k2mm_forward.sdfg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add backward pass and optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'68262a02837e7c9d01092c506345a7e1ab48f5f06a262e988fb170952f563f85'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_backward_pass(sdfg=sdfg, state=sdfg.states()[0], inputs=[\"A\"], outputs=[\"S\"])\n",
    "sdfg.simplify()\n",
    "sdfg_bwd_ao = auto_optimize(sdfg, device=DeviceType.CPU)\n",
    "sdfg.save(\"log_sdfgs/k2mm_backward.sdfg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute the SDFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdfg(alpha, beta, A, B, C, D, S, gradient_A=gradient_A, gradient_S=gradient_S)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define equivalent JAX function for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k2mm_jax(alpha, beta, A, B, C, D):\n",
    "    \"\"\"\n",
    "    JAX implementation of the k2mm operation\n",
    "    \"\"\"\n",
    "    return jnp.sum(alpha * A @ B @ C + beta * D)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute gradients using JAX and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "/home/afif/anaconda3/envs/merge_only/lib/python3.9/site-packages/numpy/core/getlimits.py:500: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/afif/anaconda3/envs/merge_only/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Array([[302.4, 302.4, 302.4, ..., 302.4, 302.4, 302.4],\n",
      "       [302.4, 302.4, 302.4, ..., 302.4, 302.4, 302.4],\n",
      "       [302.4, 302.4, 302.4, ..., 302.4, 302.4, 302.4],\n",
      "       ...,\n",
      "       [302.4, 302.4, 302.4, ..., 302.4, 302.4, 302.4],\n",
      "       [302.4, 302.4, 302.4, ..., 302.4, 302.4, 302.4],\n",
      "       [302.4, 302.4, 302.4, ..., 302.4, 302.4, 302.4]], dtype=float32),)\n"
     ]
    }
   ],
   "source": [
    "target_grad = jax.grad(k2mm_jax, argnums=[2])  # Compute gradient w.r.t A\n",
    "A = jnp.ones((NI, NK))\n",
    "B = jnp.ones((NK, NJ))\n",
    "C = jnp.ones((NJ, NL))\n",
    "D = jnp.ones((NI, NL))\n",
    "gradient_A_jax = target_grad(alpha, beta, A, B, C, D)\n",
    "print(gradient_A_jax)\n",
    "assert np.allclose(gradient_A_jax, gradient_A)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "merge_only",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
